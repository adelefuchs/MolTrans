{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making the csvs for pharos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install --upgrade pip --user\n",
    "# %pip install pandas==2.2.3\n",
    "# %pip install SQLAlchemy==2.0.0\n",
    "\n",
    "# %pip install sqlalchemy --user\n",
    "# %pip install numpy --user\n",
    "# %pip install torch \n",
    "# %pip install scikit-learn\n",
    "# %pip install mysql-connector-python --user\n",
    "# %pip install matplotlib \n",
    "# %pip install subword-nmt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reclassified proteins: 1742\n",
      "1742\n",
      "     uniprot TDL_current TDL_v6_9  fam\n",
      "0     A0AV96        Tbio    Tdark  NaN\n",
      "1     A0AVF1        Tbio    Tdark  NaN\n",
      "2     A0FGR9        Tbio    Tdark  NaN\n",
      "3     A0JNW5        Tbio    Tdark  NaN\n",
      "4     A0PJK1        Tbio    Tdark  NaN\n",
      "...      ...         ...      ...  ...\n",
      "1737  Q9Y6I8        Tbio    Tdark  NaN\n",
      "1738  Q9Y6I9        Tbio    Tdark  NaN\n",
      "1739  Q9Y6L7       Tchem    Tdark  NaN\n",
      "1740  Q9Y6Q3        Tbio    Tdark  NaN\n",
      "1741  Q9Y6V7        Tbio    Tdark  NaN\n",
      "\n",
      "[1742 rows x 4 columns]\n",
      "Number of reclassified proteins: 1742\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Define your database connection parameters\n",
    "host=\"localhost\"\n",
    "port=3306\n",
    "user=\"root\"\n",
    "password=\"Afu27959\"\n",
    "database=\"thesisCurrent\"\n",
    "database2=\"thesisv6.9\"\n",
    "\n",
    "# Create a SQLAlchemy engine\n",
    "engine1 = create_engine(f'mysql+mysqlconnector://{user}:{password}@{host}/{database}')\n",
    "\n",
    "engine2 = create_engine(f'mysql+mysqlconnector://{user}:{password}@{host}/{database2}')\n",
    "\n",
    "# Query to get data\n",
    "query1 = \"\"\"\n",
    "SELECT uniprot, tdl FROM protein JOIN target ON protein.ID = target.ID;\n",
    "\"\"\"\n",
    "df1 = pd.read_sql(query1, engine1) #Current\n",
    "#print(df1)\n",
    "\n",
    "query2 = \"\"\"\n",
    "SELECT uniprot, tdl FROM protein JOIN target ON protein.ID = target.ID;\n",
    "\"\"\"\n",
    "df2 = pd.read_sql(query2, engine2) #Older\n",
    "\n",
    "def compare_versions(df1, df2):\n",
    "    # Merge dataframes on 'uniprot'\n",
    "    merged = df1.rename(columns={'tdl': 'TDL_current'}).merge(\n",
    "        df2.rename(columns={'tdl': 'TDL_v6_9'}),\n",
    "        on='uniprot',\n",
    "        how='inner'\n",
    "    )\n",
    "    \n",
    "    # Find proteins that were Tdark in v6.9 and reclassified in v6.11\n",
    "    reclassified = merged[(merged['TDL_v6_9'] == 'Tdark') & (merged['TDL_current'] != 'Tdark')]\n",
    "    \n",
    "    return reclassified\n",
    "\n",
    "# Compare versions\n",
    "reclassified_proteins = compare_versions(df1, df2)\n",
    "\n",
    "# Display results\n",
    "print(f\"Number of reclassified proteins: {len(reclassified_proteins)}\")\n",
    "uniprot_list = reclassified_proteins['uniprot'].tolist()\n",
    "\n",
    "# Format the list for the SQL query\n",
    "formatted_uniprot_list = \"', '\".join(uniprot_list)\n",
    "print(len(uniprot_list))\n",
    "\n",
    "# Query to get family information from idg_evol table\n",
    "query_fam = f\"\"\"\n",
    "SELECT DISTINCT uniprot, fam\n",
    "FROM idg_evol\n",
    "WHERE uniprot IN ('{formatted_uniprot_list}');\n",
    "\"\"\"\n",
    "\n",
    "# Fetch the family data from the database\n",
    "fam_df = pd.read_sql(query_fam, engine1)\n",
    "\n",
    "# Merge the family data with the reclassified proteins dataframe\n",
    "reclassified_proteins_with_fam = reclassified_proteins.merge(fam_df, on='uniprot', how='left')\n",
    "\n",
    "# Display results with the added family column\n",
    "print(reclassified_proteins_with_fam)\n",
    "print(f\"Number of reclassified proteins: {len(reclassified_proteins_with_fam)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if uniprot_list:\n",
    "    # Format the list for SQL query\n",
    "    formatted_uniprot_list = \"', '\".join(uniprot_list)\n",
    "    \n",
    "    # SQL query to get relevant data from the database\n",
    "    query_data = f\"\"\"\n",
    "    SELECT \n",
    "        p.uniprot AS uniprot,\n",
    "        p.seq AS sequence,\n",
    "        da.smiles AS smiles,\n",
    "        da.act_value AS affinity\n",
    "    FROM \n",
    "        protein p\n",
    "    JOIN \n",
    "        drug_activity da ON p.id = da.target_id\n",
    "    WHERE \n",
    "        p.uniprot IN ('{formatted_uniprot_list}')\n",
    "    UNION ALL\n",
    "\n",
    "    SELECT \n",
    "        p.uniprot AS uniprot,\n",
    "        p.seq AS sequence,\n",
    "        ca.smiles AS smiles,\n",
    "        ca.act_value AS affinity\n",
    "    FROM \n",
    "        protein p\n",
    "    JOIN \n",
    "        target t ON p.id = t.id\n",
    "    JOIN \n",
    "        cmpd_activity ca ON t.id = ca.target_id\n",
    "    WHERE \n",
    "        p.uniprot IN ('{formatted_uniprot_list}')\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "498\n",
      "495\n",
      "990\n",
      "Final Pharos dataset with negative samples saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from stream import drug2emb_encoder, protein2emb_encoder\n",
    "\n",
    "# Fetch the data from the database\n",
    "data_df = pd.read_sql(query_data, engine1)\n",
    "print(len(data_df))\n",
    "\n",
    "# Rename columns as needed for MolTrans format\n",
    "data_df = data_df.rename(columns={'smiles': 'SMILES', 'sequence': 'Target Sequence'})\n",
    "\n",
    "# Select relevant columns\n",
    "data_df = data_df[['SMILES', 'Target Sequence', 'affinity']]\n",
    "\n",
    "# Remove rows with NaN or non-string SMILES values\n",
    "data_df = data_df[data_df['SMILES'].apply(lambda x: isinstance(x, str) and x.strip() != '')]\n",
    "print(len(data_df))\n",
    "\n",
    "# Treat all affinities as positive interactions\n",
    "data_df['Label'] = 1  \n",
    "#OR THRESHOLD THE AFFINITIES (NEGATIVE SAMPLES REQUIRED)\n",
    "# affinity_threshold = 7.0 \n",
    "# data_df['Label'] = (data_df['affinity'] >= affinity_threshold).astype(int)\n",
    "\n",
    "# Get unique drugs and targets\n",
    "all_drugs = data_df['SMILES'].unique()\n",
    "all_targets = data_df['Target Sequence'].unique()\n",
    "\n",
    "# Create a set of existing positive pairs for quick lookup\n",
    "positive_pairs = set(zip(data_df['SMILES'], data_df['Target Sequence']))\n",
    "\n",
    "#Generate negative samples\n",
    "num_negatives = len(data_df)  # 1:1 ratio of negatives to positives\n",
    "negative_samples = []\n",
    "np.random.seed(42)  # For reproducibility\n",
    "\n",
    "while len(negative_samples) < num_negatives:\n",
    "    drug = np.random.choice(all_drugs)\n",
    "    target = np.random.choice(all_targets)\n",
    "    \n",
    "    if (drug, target) not in positive_pairs:  # Ensure it's not a known interaction\n",
    "        negative_samples.append((drug, target, 0))  # Label 0 for negatives\n",
    "        positive_pairs.add((drug, target))  # Avoid duplicate negatives\n",
    "\n",
    "# Convert negative samples to a DataFrame\n",
    "neg_df = pd.DataFrame(negative_samples, columns=['SMILES', 'Target Sequence', 'Label'])\n",
    "\n",
    "# Concatenate positives and negatives\n",
    "final_df = pd.concat([data_df[['SMILES', 'Target Sequence', 'Label']], neg_df], ignore_index=True)\n",
    "\n",
    "# Shuffle the dataset\n",
    "final_df = final_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "#final_df = data_df\n",
    "# Initialize encoding lists\n",
    "drug_encodings, protein_encodings = [], []\n",
    "\n",
    "# Encode drugs and proteins\n",
    "for _, row in final_df.iterrows():\n",
    "    drug_encoding, _ = drug2emb_encoder(row['SMILES'])\n",
    "    protein_encoding, _ = protein2emb_encoder(row['Target Sequence'])\n",
    "    \n",
    "    drug_encodings.append(drug_encoding)\n",
    "    protein_encodings.append(protein_encoding)\n",
    "\n",
    "# Add encoded data as new columns\n",
    "final_df['drug_encoding'] = drug_encodings\n",
    "final_df['protein_encoding'] = protein_encodings\n",
    "\n",
    "# Define output path and save as CSV\n",
    "output_dir = 'dataset/pharos4DAVIS'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "final_df.to_csv(f'{output_dir}/pharos4DAVIS.csv', index=False)\n",
    "print(len(final_df))\n",
    "print(\"Final Pharos dataset with negative samples saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([495, 495]))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(final_df['Label'], return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "498\n",
      "495\n",
      "495\n",
      "Final Pharos dataset with negative samples saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from stream import drug2emb_encoder, protein2emb_encoder\n",
    "\n",
    "# Fetch the data from the database\n",
    "data_df = pd.read_sql(query_data, engine1)\n",
    "print(len(data_df))\n",
    "\n",
    "# Rename columns as needed for MolTrans format\n",
    "data_df = data_df.rename(columns={'smiles': 'SMILES', 'sequence': 'Target Sequence'})\n",
    "\n",
    "# Select relevant columns\n",
    "data_df = data_df[['SMILES', 'Target Sequence', 'affinity']]\n",
    "\n",
    "# Remove rows with NaN or non-string SMILES values\n",
    "data_df = data_df[data_df['SMILES'].apply(lambda x: isinstance(x, str) and x.strip() != '')]\n",
    "print(len(data_df))\n",
    "\n",
    "#OR THRESHOLD THE AFFINITIES (NEGATIVE SAMPLES REQUIRED)\n",
    "affinity_threshold = 7.0 \n",
    "data_df['Label'] = (data_df['affinity'] >= affinity_threshold).astype(int)\n",
    "\n",
    "final_df = data_df\n",
    "# Initialize encoding lists\n",
    "drug_encodings, protein_encodings = [], []\n",
    "\n",
    "# Encode drugs and proteins\n",
    "for _, row in final_df.iterrows():\n",
    "    drug_encoding, _ = drug2emb_encoder(row['SMILES'])\n",
    "    protein_encoding, _ = protein2emb_encoder(row['Target Sequence'])\n",
    "    \n",
    "    drug_encodings.append(drug_encoding)\n",
    "    protein_encodings.append(protein_encoding)\n",
    "\n",
    "# Add encoded data as new columns\n",
    "final_df['drug_encoding'] = drug_encodings\n",
    "final_df['protein_encoding'] = protein_encodings\n",
    "\n",
    "# Define output path and save as CSV\n",
    "output_dir = 'dataset/pharos4DAVIS'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "final_df.to_csv(f'{output_dir}/pharos4DAVIS_allp.csv', index=False)\n",
    "print(len(final_df))\n",
    "print(\"Final Pharos dataset with negative samples saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([ 76, 419]))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(final_df['Label'], return_counts=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pvenv)",
   "language": "python",
   "name": "pvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
